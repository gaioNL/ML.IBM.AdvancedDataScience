{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
    "\n",
    "\n",
    "if ('sc' in locals() or 'sc' in globals()):\n",
    "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark==2.4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
      "\u001b[K     |████████████████████████████████| 217.8MB 142kB/s  eta 0:00:01     |█████████████████████████▍      | 172.5MB 41.6MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark==2.4.5)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 33.2MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MEAN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,4,5,34,1,32,4,34,2,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.250\n"
     ]
    }
   ],
   "source": [
    "sum = rdd.sum()\n",
    "count = rdd.count()\n",
    "mean = sum / count\n",
    "print('%.3f'%mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***MEDIAN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 2), (4, 2), (5, 3), (6, 4), (7, 4), (8, 5), (9, 32), (10, 34), (11, 34)] 12\n"
     ]
    }
   ],
   "source": [
    "ord = rdd.sortBy(lambda x : x ).zipWithIndex().map(lambda x: (x[1],x[0])).collect()\n",
    "print (ord,len(ord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "3.500\n"
     ]
    }
   ],
   "source": [
    "n = len(ord)\n",
    "if (n % 2 ==1):\n",
    "    index = int((n-1)/2)\n",
    "    print( ord[index][1])\n",
    "else:\n",
    "    index1 = int((n/2)-1)\n",
    "    index2 = int((n/2))\n",
    "    print( ord[index1][1])\n",
    "    print( ord[index2][1])\n",
    "    val1 = ord[index1][1]\n",
    "    val2 = ord[index2][1]\n",
    "    med = (val1 + val2)/2\n",
    "    print('%.3f'%med)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***STANDARD DEVIATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.800\n"
     ]
    }
   ],
   "source": [
    "#standard deviation\n",
    "rdd1 = sc.parallelize([34,1,23,4,3,3,12,4,3,1])\n",
    "sum = rdd1.sum()\n",
    "count1 = rdd1.count()\n",
    "mean1 = sum / count1\n",
    "print('%.3f'%mean1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.562196741208714\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "print(sqrt(rdd1.map(lambda x: pow(x-mean1,2)).sum()/count1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***KURTOSIS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.parallelize([34,1,23,4,3,3,12,4,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.800\n"
     ]
    }
   ],
   "source": [
    "#mean\n",
    "sum = rdd2.sum()\n",
    "count2 = rdd2.count()\n",
    "mean2 = sum / count2\n",
    "print('%.3f'%mean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.562196741208714\n"
     ]
    }
   ],
   "source": [
    "#std\n",
    "from math import sqrt\n",
    "std=sqrt(rdd2.map(lambda x: pow(x-mean2,2)).sum()/count2)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.663124005193276\n"
     ]
    }
   ],
   "source": [
    "kt = rdd2.map(lambda x : pow(x-mean2,4)/pow(std,4)).sum()/count2\n",
    "print(kt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Skewness***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4549069329914\n"
     ]
    }
   ],
   "source": [
    "sk = rdd2.map(lambda x : pow(x-mean2,3)/pow(std,3)).sum()/count2\n",
    "print(sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rddX = sc.parallelize(random.sample(range(100),100))\n",
    "rddY = sc.parallelize(random.sample(range(100),100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanX 49.50000\n",
      "meanY 49.50000\n"
     ]
    }
   ],
   "source": [
    "meanX = rddX.sum()/rddX.count()\n",
    "meanY = rddY.sum()/rddY.count()\n",
    "print(\"meanX {:.5f}\".format(meanX))\n",
    "print(\"meanY {:.5f}\".format(meanY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 88),\n",
       " (39, 96),\n",
       " (62, 43),\n",
       " (35, 0),\n",
       " (80, 39),\n",
       " (23, 91),\n",
       " (63, 60),\n",
       " (52, 68),\n",
       " (59, 15),\n",
       " (47, 57)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddXY = rddX.zip(rddY)\n",
    "rddXY.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***COVARIANCE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.96\n"
     ]
    }
   ],
   "source": [
    "covXY = rddXY.map(lambda x : (x[0]-meanX)*(x[1]-meanY)).sum()/rddXY.count()\n",
    "print(covXY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanX 5.50000\n",
      "meanY 6.70000\n",
      "3.65\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rddX = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "rddY = sc.parallelize([7,6,5,4,5,6,7,8,9,10])\n",
    "meanX = rddX.sum()/rddX.count()\n",
    "meanY = rddY.sum()/rddY.count()\n",
    "print(\"meanX {:.5f}\".format(meanX))\n",
    "print(\"meanY {:.5f}\".format(meanY))\n",
    "rddXY = rddX.zip(rddY)\n",
    "rddXY.take(10)\n",
    "covXY = rddXY.map(lambda x : (x[0]-meanX)*(x[1]-meanY)).sum()/rddXY.count()\n",
    "print(covXY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CORRELATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06595859585958595"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = rddXY.count()\n",
    "stdX=sqrt(rddX.map(lambda x: pow(x-meanX,2)).sum()/n)\n",
    "stdY=sqrt(rddX.map(lambda x: pow(x-meanY,2)).sum()/n)\n",
    "corrXY = covXY/(stdX * stdY)\n",
    "corrXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CORRELATION MATRIX***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "col1 = sc.parallelize(range(100))\n",
    "col2 = sc.parallelize(range(100,200))\n",
    "col3 = sc.parallelize(list(reversed(range(100))))\n",
    "col4 = sc.parallelize(random.sample(range(100),100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 100, 99, 61],\n",
       " [1, 101, 98, 0],\n",
       " [2, 102, 97, 64],\n",
       " [3, 103, 96, 16],\n",
       " [4, 104, 95, 86],\n",
       " [5, 105, 94, 15],\n",
       " [6, 106, 93, 66],\n",
       " [7, 107, 92, 91],\n",
       " [8, 108, 91, 19],\n",
       " [9, 109, 90, 46]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = col1.zip(col2).zip(col3).zip(col4).map(lambda x : (x[0][0][0],x[0][0][1],x[0][1],x[1])).map(lambda x: [x[0],x[1],x[2],x[3]])\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -1.        , -0.01306931],\n",
       "       [ 1.        ,  1.        , -1.        , -0.01306931],\n",
       "       [-1.        , -1.        ,  1.        ,  0.01306931],\n",
       "       [-0.01306931, -0.01306931,  0.01306931,  1.        ]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanX 5.50000\n",
      "meanY 6.70000\n",
      "3.65\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rddX = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "rddY = sc.parallelize([7,6,5,4,5,6,7,8,9,10])\n",
    "meanX = rddX.sum()/rddX.count()\n",
    "meanY = rddY.sum()/rddY.count()\n",
    "print(\"meanX {:.5f}\".format(meanX))\n",
    "print(\"meanY {:.5f}\".format(meanY))\n",
    "rddXY = rddX.zip(rddY)\n",
    "covXY = rddXY.map(lambda x : (x[0]-meanX)*(x[1]-meanY)).sum()/rddXY.count()\n",
    "print(covXY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40822913961171386\n"
     ]
    }
   ],
   "source": [
    "n = rddXY.count()\n",
    "stdX=sqrt(rddX.map(lambda x: pow(x-meanX,2)).sum()/n)\n",
    "stdY=sqrt(rddX.map(lambda x: pow(x-meanY,2)).sum()/n)\n",
    "corrXY = covXY/(stdX * stdY)\n",
    "print(corrXY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
